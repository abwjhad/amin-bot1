import telebot
import sqlite3
import requests
import time
import os
import threading
import html
import random
import json
import hashlib
import logging
from datetime import datetime
import google.generativeai as genai

# ==========================================
# âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# ==========================================
TOKEN = "6396872015:AAHQCVV0NKKAUx0jw4Un3e6YcuUGU19jd1M"
GEMINI_KEY = "AIzaSyABXhnU1tRmhuuL9FyRAtY-qGRdtQr-xiE"
ADMIN_ID = 5509592307
MAIN_CHANNEL = "@Yemen_International_Library"
LIB_LINK = "https://t.me/Yemen_International_Library"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ Railway
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ù…Ù†Ø§ÙŠ
genai.configure(api_key=GEMINI_KEY)
ai_model = genai.GenerativeModel('gemini-1.5-flash')

bot = telebot.TeleBot(TOKEN)

# --- Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù€ Volume (ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø§Ù… Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©) ---
db_path = "/data/billion_lib.db"
archive_path = "/data/archive.json"

# ==========================================
# ğŸ­ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ (Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù€ 50 Ø£Ø³Ù„ÙˆØ¨Ø§Ù‹)
# ==========================================
PROMPT_STYLES = [
    {"id": 1, "name": "Ø¹Ø§Ù„Ù… Ø£Ù†Ø«Ø±ÙˆØ¨ÙˆÙ„ÙˆØ¬ÙŠØ§", "template": "Ø­Ù„Ù„ ÙƒØªØ§Ø¨ '{book}' ÙƒØ¸Ø§Ù‡Ø±Ø© Ù…Ø¬ØªÙ…Ø¹ÙŠØ©. Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙŠÙƒØ´ÙÙ‡ Ø¹Ù† Ø§Ù„Ø«Ù‚Ø§ÙØ©ØŸ"},
    {"id": 2, "name": "Ù…Ø®ØªØ±Ø¹ Ø¹Ø¨Ù‚Ø±ÙŠ", "template": "ÙƒÙŠÙ Ù†Ø­ÙˆÙ„ Ø£ÙÙƒØ§Ø± '{book}' Ù„Ø§Ø®ØªØ±Ø§Ø¹Ø§Øª Ø¹Ù…Ù„ÙŠØ©ØŸ"},
    {"id": 3, "name": "Ø±Ø­Ø§Ù„Ø© Ù…Ø³ØªÙƒØ´Ù", "template": "ÙˆØµÙ Ø±Ø­Ù„ØªÙƒ Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§ÙÙŠØ© Ø¹Ø¨Ø± ÙƒØªØ§Ø¨ '{book}' ÙˆØ§Ù„ÙƒÙ†ÙˆØ² Ø§Ù„ØªÙŠ ÙˆØ¬Ø¯ØªÙ‡Ø§."},
    {"id": 4, "name": "Ø·Ø¨ÙŠØ¨ Ù†ÙØ³ÙŠ", "template": "Ø´Ø®Øµ Ø§Ù„ÙØ§Ø¦Ø¯Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ù„ÙƒØªØ§Ø¨ '{book}' ÙˆÙƒÙŠÙ ÙŠØ¯Ø§ÙˆÙŠ Ø§Ù„Ø¹Ù‚Ù„ØŸ"},
    {"id": 5, "name": "Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø¹Ù…Ø§Ø±ÙŠ", "template": "ØµÙ…Ù… Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙƒØ±ÙŠ Ù„ÙƒØªØ§Ø¨ '{book}' ÙˆØ§Ù„Ø£Ø³Ø³ Ø§Ù„ØªÙŠ ÙŠØ±ØªÙƒØ² Ø¹Ù„ÙŠÙ‡Ø§."},
    # ... ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¨Ù‚ÙŠØ© Ø§Ù„Ù€ 50 Ø£Ø³Ù„ÙˆØ¨Ø§Ù‹ Ù‡Ù†Ø§ Ø¨Ù†ÙØ³ Ø§Ù„Ù†Ù…Ø·
]

# ==========================================
# ğŸ“ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø±Ø´ÙŠÙ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ==========================================
class PersistentArchive:
    def __init__(self):
        if not os.path.exists("/data"):
            os.makedirs("/data", exist_ok=True)
        self.load()

    def load(self):
        try:
            if os.path.exists(archive_path):
                with open(archive_path, 'r', encoding='utf-8') as f:
                    self.data = json.load(f)
            else:
                self.data = {"books": [], "published_count": 0}
        except:
            self.data = {"books": [], "published_count": 0}

    def save(self):
        with open(archive_path, 'w', encoding='utf-8') as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)

archive = PersistentArchive()

# ==========================================
# ğŸ§  Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø·ÙˆØ±)
# ==========================================
def get_smart_analysis(book_name):
    style = random.choice(PROMPT_STYLES)
    prompt = f"""
    Ø£Ù†Øª ØªØªØ­Ø¯Ø« Ø¨Ø£Ø³Ù„ÙˆØ¨: {style['name']}
    Ø­Ù„Ù„ ÙƒØªØ§Ø¨: '{book_name}'
    Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø±Ø¯ JSON Ø­ØµØ±Ø§Ù‹ Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„ØªØ§Ù„ÙŠØ©:
    {{
      "cat": "ØªØµÙ†ÙŠÙ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…Ø¨ØªÙƒØ±",
      "desc": "Ù†Ø¨Ø°Ø© ØªØ¬ÙŠØ¨: Ù„Ù…Ø§Ø°Ø§ ÙŠØ­ØªØ§Ø¬ Ø§Ù„Ù‚Ø§Ø±Ø¦ Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨ØŸ ÙˆÙ…Ø§ Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø°ÙŠ Ø³ÙŠØ­Ø¯Ø« Ù„Ù‡ØŸ (Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Ø§Øª Ù…ÙƒØ±Ø±Ø©)",
      "wisdom": "Ø¯Ø±Ø© Ø£Ùˆ Ø­ÙƒÙ…Ø© ÙØ±ÙŠØ¯Ø© ØªÙ†Ø§Ø³Ø¨ Ø§Ù„ÙƒØªØ§Ø¨"
    }}
    """
    try:
        response = ai_model.generate_content(prompt)
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù„Ø¶Ù…Ø§Ù† Ø£Ù†Ù‡ JSON ØµØ§Ù„Ø­
        clean_text = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(clean_text), style['name']
    except Exception as e:
        logger.error(f"AI Error: {e}")
        return {
            "cat": "Ø«Ù‚Ø§ÙØ© ÙˆÙ…Ø¹Ø±ÙØ©",
            "desc": "ÙƒØªØ§Ø¨ ÙŠÙØªØ­ Ø¢ÙØ§Ù‚Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø±Ø­Ù„ØªÙƒ Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ© ÙˆÙŠØ¶ÙŠÙ Ù„Ø¹Ù…Ù‚Ùƒ Ø§Ù„ÙÙƒØ±ÙŠ.",
            "wisdom": "Ø®ÙŠØ± Ø¬Ù„ÙŠØ³ ÙÙŠ Ø§Ù„Ø²Ù…Ø§Ù† ÙƒØªØ§Ø¨"
        }, "Ø£Ø³Ù„ÙˆØ¨ Ø¹Ø§Ù…"

# ==========================================
# ğŸ› ï¸ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø¨ÙˆØª
# ==========================================
def init_db():
    conn = sqlite3.connect(db_path)
    conn.execute('''CREATE TABLE IF NOT EXISTS files 
                 (hash TEXT PRIMARY KEY, name TEXT, file_id TEXT, status TEXT)''')
    conn.commit()
    conn.close()

@bot.message_handler(content_types=['document'])
def handle_docs(message):
    if message.from_user.id != ADMIN_ID: return
    
    f = message.document
    f_hash = hashlib.md5(f"{f.file_name}_{f.file_size}".encode()).hexdigest()
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT hash FROM files WHERE hash=?", (f_hash,))
    
    if cursor.fetchone():
        bot.reply_to(message, "âš ï¸ Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹.")
    else:
        cursor.execute("INSERT INTO files VALUES (?, ?, ?, ?)", (f_hash, f.file_name, f.file_id, 'pending'))
        conn.commit()
        bot.reply_to(message, f"âœ… ØªÙ…Øª Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©: {f.file_name}")
        archive.data["books"].append({"name": f.file_name, "hash": f_hash})
        archive.save()
    conn.close()

# ==========================================
# ğŸš€ Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
# ==========================================
def publisher_loop():
    while True:
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT hash, name, file_id FROM files WHERE status='pending' LIMIT 1")
            task = cursor.fetchone()
            
            if task:
                h, name, fid = task
                clean_name = name.replace('.pdf', '').replace('_', ' ')
                
                ai_data, style_name = get_smart_analysis(clean_name)
                
                caption = f"""
ğŸ“š <b>{clean_name}</b>

ğŸ“‚ <b>Ø§Ù„ØªØµÙ†ÙŠÙ:</b> {ai_data.get('cat', 'Ù…Ø¹Ø±ÙØ©')}

ğŸ“– <b>Ù„Ù…Ø§Ø°Ø§ ØªÙ‚Ø±Ø£ Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨ØŸ</b>
{ai_data.get('desc', '')}

ğŸ’ <b>Ø¯Ø±Ø±:</b> <i>{ai_data.get('wisdom', '')}</i>

ğŸ­ <b>Ø§Ù„Ø£Ø³Ù„ÙˆØ¨:</b> {style_name}
ğŸ›ï¸ <a href='{LIB_LINK}'>Ù…ÙƒØªØ¨Ø© Ø§Ù„Ù…Ù„ÙŠØ§Ø± ÙƒØªØ§Ø¨</a>
                """
                
                bot.send_document(MAIN_CHANNEL, fid, caption=caption, parse_mode="HTML")
                
                cursor.execute("UPDATE files SET status='published' WHERE hash=?", (h,))
                conn.commit()
                archive.data["published_count"] += 1
                archive.save()
                
                bot.send_message(ADMIN_ID, f"âœ… ØªÙ… Ù†Ø´Ø±: {clean_name}\nğŸ­ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: {style_name}")
                time.sleep(30) # ÙØ§ØµÙ„ Ø²Ù…Ù†ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª
            else:
                time.sleep(10)
            conn.close()
        except Exception as e:
            logger.error(f"Publisher Loop Error: {e}")
            time.sleep(10)

# ==========================================
# ğŸ“Š Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªØ­ÙƒÙ…
# ==========================================
@bot.message_handler(commands=['stats'])
def send_stats(message):
    if message.from_user.id != ADMIN_ID: return
    total = archive.data["published_count"]
    bot.reply_to(message, f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ø¯Ø§Ø¦Ù…:\nâœ… Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø©: {total}")

if __name__ == "__main__":
    init_db()
    threading.Thread(target=publisher_loop, daemon=True).start()
    logger.info("ğŸ¤– Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø·ÙˆØ±...")
    bot.infinity_polling()
